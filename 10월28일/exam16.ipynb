{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "\n",
    "# 스케일러 객체를 만듭니다.\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# 특성의 스케일을 변환합니다.\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "# 특성을 출력합니다.\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트를 변환합니다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트를 변환합니다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트로 변환기를 학습합니다.\n",
    "scaler = preprocessing.MinMaxScaler().fit(feature[:3])\n",
    "scaler.transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트에서 학습한 변환기로 테스트 세트를 변환합니다.\n",
    "scaler.transform(feature[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "x = np.array([[-1000.1],\n",
    "              [-200.2],\n",
    "              [500.5],\n",
    "              [600.6],\n",
    "              [9000.9]])\n",
    "\n",
    "# 변환기 객체를 만듭니다.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# 특성을 변환합니다.\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "# 특성을 출력합니다.\n",
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균과 표준 편차를 출력합니다.\n",
    "print(\"평균 Mean:\", round(standardized.mean()))\n",
    "print(\"표준 편차 Standard deviation:\", standardized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 객체를 만듭니다.\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# 특성을 변환합니다.\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interquatile_range = x[3] - x[1]\n",
    "(x - np.median(x)) / interquatile_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.QuantileTransformer().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# 특성 행렬을 만듭니다.\n",
    "features = np.array([[0.5, 0.5],\n",
    "                     [1.1, 3.4],\n",
    "                     [1.5, 20.2],\n",
    "                     [1.63, 34.4],\n",
    "                     [10.9, 3.3]])\n",
    "\n",
    "# 변환기 객체를 만듭니다.\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "\n",
    "# 특성 행렬을 변환합니다.\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 행렬을 변환합니다.\n",
    "features_l2_norm = Normalizer(norm=\"l2\").transform(features)\n",
    "\n",
    "# 특성 행렬을 출력합니다.\n",
    "features_l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 행렬을 변환합니다.\n",
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "\n",
    "# 특성 행렬을 출력합니다.\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합을 출력합니다.\n",
    "print(\"첫 번째 샘플 값의 합:\",\n",
    "   features_l1_norm[0, 0] + features_l1_norm[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 노름을 사용한 변환.\n",
    "# 각 행(axis=1)을 합한 결과가 2차원 배열로 유지되도록 keepdims를 True로 설정합니다.\n",
    "features / np.sum(np.abs(features), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 노름을 사용한 변환.\n",
    "features / np.sqrt(np.sum(np.square(features), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행에서 최댓값으로 나눕니다.\n",
    "Normalizer(norm=\"max\").transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 특성 행렬을 만듭니다.\n",
    "features = np.array([[2, 3],\n",
    "                     [2, 3],\n",
    "                     [2, 3]])\n",
    "\n",
    "# PolynomialFeatures 객체를 만듭니다.\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# 다항 특성을 만듭니다.\n",
    "polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = PolynomialFeatures(degree=2, \n",
    "                                 interaction_only=True, include_bias=False)\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수항 1을 추가합니다.\n",
    "polynomial_bias = PolynomialFeatures(degree=2, include_bias=True).fit(features)\n",
    "polynomial_bias.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_bias.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# 특성 행렬을 만듭니다.\n",
    "features = np.array([[2, 3],\n",
    "                     [2, 3],\n",
    "                     [2, 3]])\n",
    "\n",
    "# 간단한 함수를 정의합니다.\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "\n",
    "# 변환기 객체를 만듭니다.\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "# 특성 행렬을 변환합니다.\n",
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임을 만듭니다.\n",
    "df = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "# 함수를 적용합니다.\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FunctionTransformer(add_ten, validate=False).transform(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 100을 더하는 함수를 만듭니다.\n",
    "def add_hundred(x):\n",
    "    return x + 100\n",
    "\n",
    "# (이름, 변환기, 열 리스트)로 구성된 튜플의 리스트를 ColumnTransformer에 전달합니다.\n",
    "ct = ColumnTransformer(\n",
    "    [(\"add_ten\", FunctionTransformer(add_ten, validate=True), ['feature_1']),\n",
    "     (\"add_hundred\", FunctionTransformer(add_hundred, validate=True), ['feature_2'])])\n",
    "\n",
    "ct.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# 모의 데이터를 만듭니다.\n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "                         n_features = 2,\n",
    "                         centers = 1,\n",
    "                         random_state = 1)\n",
    "\n",
    "# 첫 번째 샘플을 극단적인 값으로 바꿉니다.\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000\n",
    "\n",
    "# 이상치 감지 객체를 만듭니다.\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "\n",
    "# 감지 객체를 훈련합니다.\n",
    "outlier_detector.fit(features)\n",
    "\n",
    "# 이상치를 예측합니다.\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 특성을 만듭니다.\n",
    "feature = features[:,0]\n",
    "\n",
    "# 이상치의 인덱스를 반환하는 함수를 만듭니다.\n",
    "def indicies_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((x > upper_bound) | (x < lower_bound))\n",
    "\n",
    "# 함수를 실행합니다.\n",
    "indicies_of_outliers(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임을 만듭니다.\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000]\n",
    "\n",
    "# 샘플을 필터링합니다.\n",
    "houses[houses['Bathrooms'] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "\n",
    "# 불리언 조건을 기반으로 특성을 만듭니다.\n",
    "houses[\"Outlier\"] = np.where(houses[\"Bathrooms\"] < 20, 0, 1)\n",
    "\n",
    "# 데이터를 확인합니다.\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 특성\n",
    "houses[\"Log_Of_Square_Feet\"] = [np.log(x) for x in houses[\"Square_Feet\"]]\n",
    "\n",
    "# 데이터를 확인합니다.\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "age = np.array([[6],\n",
    "                [12],\n",
    "                [20],\n",
    "                [36],\n",
    "                [65]])\n",
    "\n",
    "# Binarizer 객체를 만듭니다.\n",
    "binarizer = Binarizer(threshold=18)\n",
    "\n",
    "# 특성을 변환합니다.\n",
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성을 나눕니다.\n",
    "np.digitize(age, bins=[20,30,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성을 나눕니다.\n",
    "np.digitize(age, bins=[20,30,64], right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성을 나눕니다.\n",
    "np.digitize(age, bins=[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# 네 개의 구간으로 나눕니다.\n",
    "kb = KBinsDiscretizer(4, encode='ordinal', strategy='quantile')\n",
    "kb.fit_transform(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩을 반환합니다.\n",
    "kb = KBinsDiscretizer(4, encode='onehot-dense', strategy='quantile')\n",
    "kb.fit_transform(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 길이의 구간을 만듭니다.\n",
    "kb = KBinsDiscretizer(4, encode='onehot-dense', strategy='uniform')\n",
    "kb.fit_transform(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 모의 특성 행렬을 만듭니다.\n",
    "features, _ = make_blobs(n_samples = 50,\n",
    "                         n_features = 2,\n",
    "                         centers = 3,\n",
    "                         random_state = 1)\n",
    "\n",
    "# 데이터프레임을 만듭니다.\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "# k-평균 군집 모델을 만듭니다.\n",
    "clusterer = KMeans(3, random_state=0)\n",
    "\n",
    "# 모델을 훈련합니다.\n",
    "clusterer.fit(features)\n",
    "\n",
    "# 그룹 소속을 예측합니다.\n",
    "dataframe[\"group\"] = clusterer.predict(features)\n",
    "\n",
    "# 처음 몇 개의 샘플을 조회합니다.\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "\n",
    "# 특성 행렬을 만듭니다.\n",
    "features = np.array([[1.1, 11.1],\n",
    "                     [2.2, 22.2],\n",
    "                     [3.3, 33.3],\n",
    "                     [4.4, 44.4],\n",
    "                     [np.nan, 55]])\n",
    "\n",
    "# (~ 연산자를 사용하여) 누락된 값이 없는 샘플만 남깁니다.\n",
    "features[~np.isnan(features).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 적재합니다.\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "# 누락된 값이 있는 샘플을 제거합니다.\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# 모의 특성 행렬을 만듭니다.\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "                         n_features = 2,\n",
    "                         random_state = 1)\n",
    "\n",
    "# 특성을 표준화합니다.\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "# 첫 번째 샘플의 첫 번째 특성을 삭제합니다.\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan\n",
    "\n",
    "# 특성 행렬에 있는 누락된 값을 예측합니다.\n",
    "features_knn_imputed = KNN(k=5, verbose=0).fit_transform(standardized_features)\n",
    "\n",
    "# 실제 값과 대체된 값을 비교합니다.\n",
    "print(\"실제 값:\", true_value)\n",
    "print(\"대체된 값:\", features_knn_imputed[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 0.22 버전에서 `Imputer` 클래스가 삭제되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 라이브러리를 임포트합니다.\n",
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "# # Imputer 객체를 만듭니다.\n",
    "# mean_imputer = Imputer(strategy=\"mean\", axis=0)\n",
    "\n",
    "# # 누락된 값을 채웁니다.\n",
    "# features_mean_imputed = mean_imputer.fit_transform(features)\n",
    "\n",
    "# # 실제 값과 대체된 값을 비교합니다.\n",
    "# print(\"실제 값 True Value:\", true_value)\n",
    "# print(\"대체된 값 Imputed Value:\", features_mean_imputed[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "simple_imputer = SimpleImputer()\n",
    "features_simple_imputed = simple_imputer.fit_transform(features)\n",
    "\n",
    "# 실제 값과 대체된 값을 비교합니다.\n",
    "print(\"실제 값 True Value:\", true_value)\n",
    "print(\"대체된 값 Imputed Value:\", features_simple_imputed[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
