{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "feature = np.array([[\"Texas\"],\n",
    "                    [\"California\"],\n",
    "                    [\"Texas\"],\n",
    "                    [\"Delaware\"],\n",
    "                    [\"Texas\"]])\n",
    "\n",
    "# 원-핫 인코더를 만듭니다.\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "# 특성을 원-핫 인코딩합니다.\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성의 클래스를 확인합니다.\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩을 되돌립니다.\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import pandas as pd\n",
    "\n",
    "# 특성으로 더미(dummy) 변수를 만듭니다.\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 특성을 만듭니다.\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"),\n",
    "                      (\"California\", \"Alabama\"),\n",
    "                      (\"Texas\", \"Florida\"),\n",
    "                      (\"Delware\", \"Florida\"),\n",
    "                      (\"Texas\", \"Alabama\")]\n",
    "\n",
    "# 다중 클래스 원-핫 인코더를 만듭니다.\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "\n",
    "# 다중 클래스 특성을 원-핫 인코딩합니다.\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스를 확인합니다.\n",
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 여러 개의 열이 있는 특성 배열을 만듭니다.\n",
    "feature = np.array([[\"Texas\", 1],\n",
    "                    [\"California\", 1],\n",
    "                    [\"Texas\", 3],\n",
    "                    [\"Delaware\", 1],\n",
    "                    [\"Texas\", 1]])\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import pandas as pd\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "dataframe = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
    "\n",
    "# 매핑 딕셔너리를 만듭니다.\n",
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"High\":3}\n",
    "\n",
    "# 특성을 정수로 변환합니다.\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\"Score\": [\"Low\",\n",
    "                                    \"Low\",\n",
    "                                    \"Medium\",\n",
    "                                    \"Medium\",\n",
    "                                    \"High\",\n",
    "                                    \"Barely More Than Medium\"]})\n",
    "\n",
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"Barely More Than Medium\": 3,\n",
    "                \"High\":4}\n",
    "\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"Barely More Than Medium\": 2.1,\n",
    "                \"High\":3}\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "features = np.array([[\"Low\", 10],\n",
    "                     [\"High\", 50],\n",
    "                     [\"Medium\", 3]])\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# 딕셔너리를 만듭니다.\n",
    "data_dict = [{\"Red\": 2, \"Blue\": 4},\n",
    "             {\"Red\": 4, \"Blue\": 3},\n",
    "             {\"Red\": 1, \"Yellow\": 2},\n",
    "             {\"Red\": 2, \"Yellow\": 2}]\n",
    "\n",
    "# DictVectorizer 객체를 만듭니다.\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# 딕셔너리를 특성 행렬로 변환합니다.\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "# 특성 행렬을 확인합니다.\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 이름을 얻습니다.\n",
    "feature_names = dictvectorizer.get_feature_names()\n",
    "\n",
    "# 특성 이름을 확인합니다.\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import pandas as pd\n",
    "\n",
    "# 특성으로 데이터프레임을 만듭니다.\n",
    "pd.DataFrame(features, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네 개의 문서에 대한 단어 카운트 딕셔너리를 만듭니다.\n",
    "doc_1_word_count = {\"Red\": 2, \"Blue\": 4}\n",
    "doc_2_word_count = {\"Red\": 4, \"Blue\": 3}\n",
    "doc_3_word_count = {\"Red\": 1, \"Yellow\": 2}\n",
    "doc_4_word_count = {\"Red\": 2, \"Yellow\": 2}\n",
    "\n",
    "# 리스트를 만듭니다.\n",
    "doc_word_counts = [doc_1_word_count,\n",
    "                   doc_2_word_count,\n",
    "                   doc_3_word_count,\n",
    "                   doc_4_word_count]\n",
    "\n",
    "# 단어 카운트 딕셔너리를 특성 행렬로 변환합니다.\n",
    "dictvectorizer.fit_transform(doc_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 범주형 특성을 가진 특성 행렬을 만듭니다.\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "              [1, 1.18, 1.33],\n",
    "              [0, 1.22, 1.27],\n",
    "              [1, -0.21, -1.19]])\n",
    "\n",
    "# 범주형 특성에 누락된 값이 있는 특성 행렬을 만듭니다.\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                       [np.nan, -0.67, -0.22]])\n",
    "\n",
    "# KNN 학습기를 훈련합니다.\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "# 누락된 값의 클래스를 예측합니다.\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
    "\n",
    "# 예측된 클래스와 원본 특성을 열로 합칩니다.\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "\n",
    "# 두 특성 행렬을 연결합니다.\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 두 개의 특성 행렬을 합칩니다.\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 붓꽃 데이터를 적재합니다.\n",
    "iris = load_iris()\n",
    "\n",
    "# 특성 행렬을 만듭니다.\n",
    "features = iris.data\n",
    "\n",
    "# 타깃 벡터를 만듭니다.\n",
    "target = iris.target\n",
    "\n",
    "# 처음 40개 샘플을 삭제합니다.\n",
    "features = features[40:,:]\n",
    "target = target[40:]\n",
    "\n",
    "# 클래스 0을 음성 클래스로 하는 이진 타깃 벡터를 만듭니다.\n",
    "target = np.where((target == 0), 0, 1)\n",
    "\n",
    "# 불균형한 타깃 벡터를 확인합니다.\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치를 만듭니다.\n",
    "weights = {0: .9, 1: 0.1}\n",
    "\n",
    "# 가중치를 부여한 랜덤 포레스트 분류기를 만듭니다.\n",
    "RandomForestClassifier(class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 균형잡힌 클래스 가중치로 랜덤 포레스트 모델을 훈련합니다.\n",
    "RandomForestClassifier(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스의 샘플 인덱스를 추출합니다.\n",
    "i_class0 = np.where(target == 0)[0]\n",
    "i_class1 = np.where(target == 1)[0]\n",
    "\n",
    "# 각 클래스의 샘플 개수\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "# 클래스 0의 샘플만큼 클래스 1에서 중복을 허용하지 않고 랜덤하게 샘플을 뽑습니다.\n",
    "# from class 1 without replacement\n",
    "i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "\n",
    "# 클래스 0의 타깃 벡터와 다운샘플링된 클래스 1의 타깃 벡터를 합칩니다.\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((features[i_class0,:], features[i_class1_downsampled,:]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 1의 샘플 개수만큼 클래스 0에서 중복을 허용하여 랜덤하게 샘플을 선택합니다.\n",
    "i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True)\n",
    "\n",
    "# 클래스 0의 업샘플링된 타깃 벡터와 클래스 1의 타깃 벡터를 합칩니다.\n",
    "np.concatenate((target[i_class0_upsampled], target[i_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 0의 업샘플링된 특성 행렬과 클래스 1의 특성 행렬을 합칩니다.\n",
    "np.vstack((features[i_class0_upsampled,:], features[i_class1,:]))[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
