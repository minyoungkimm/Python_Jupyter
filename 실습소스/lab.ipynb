{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿<!DOCTYPE html>\n",
      "<html>  \n",
      "  <head>    \n",
      "   <meta charset=\"utf-8\">    \n",
      "   <title>TEST</title>  \n",
      "  </head>  \n",
      "  <body>   \n",
      "    <h1 style='color : red'>카테고리 : 역사</h1>\n",
      "    <h2 style='color : blue'>페이지 : 25</h2>   \n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "params = urllib.parse.urlencode({'category': '역사', 'page': 25})\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/exercise.php?%s\" % params\n",
    "with urllib.request.urlopen(url) as f:     \n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿<!DOCTYPE html>\n",
      "<html>  \n",
      "  <head>    \n",
      "   <meta charset=\"utf-8\">    \n",
      "   <title>TEST</title>  \n",
      "  </head>  \n",
      "  <body>   \n",
      "    <h1 style='color : red'>카테고리 : 여행</h1>\n",
      "    <h2 style='color : blue'>페이지 : 100</h2>   \n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "dicdata = {'category': '여행', 'page': '100'}\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/exercise.php'\n",
    "r = requests.get(urlstr, params=dicdata)\n",
    "r.encoding = 'utf-8'\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1> 태그의 컨텐트]  HTML의 링크 태그\n",
      "[텍스트 형식으로 내용을 가지고 있는 <a> 태그의 컨텐트와 href 속성값] \n",
      "World Wide Consortium  :  http://www.w3.org/\n",
      "Java Page  :  http://java.sun.com/\n",
      "Python Page  :  http://www.python.org/\n",
      "Web Client 기술 학습  :  http://www.w3schools.com/\n",
      "[<img> 태그의 src 속성값]  http://unico2013.dothome.co.kr/image/duke.jpg\n",
      "[첫 번째 <h2> 태그의 컨텐트]  좋아하는 색\n",
      "[<ul> 태그의 자식 태그들중 style 속성의 값이 green으로 끝나는 태그의 컨텐트]  녹색\n",
      "[두 번째 <h2> 태그의 컨텐트]  먹고싶은 음식\n",
      "[<ol> 태그의 모든 자식 태그들의 컨텐트 ]\n",
      "짜장면\n",
      "냉면\n",
      "돈까스\n",
      "갈비\n",
      "[<table> 태그의 모든 자손 태그들의 컨텐트 ]\n",
      "둘리또치도우너\n",
      "케라토사우루스타조외계인\n",
      "도봉구 쌍문동아프리카깐따삐아 별\n",
      "[name이라는 클래스 속성을 갖는 <tr> 태그의 컨텐트]  둘리또치도우너\n",
      "[target이라는 아이디 속성을 갖는 <td> 태그의 컨텐트]  아프리카\n"
     ]
    }
   ],
   "source": [
    "#파일명 : exercise_solution.py\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/exercise_bs.html\" \n",
    "html = urllib.request.urlopen(url)\n",
    "bs = BeautifulSoup(html.read().decode('utf-8'), \"html.parser\")\n",
    "#bs = BeautifulSoup(html, \"html.parser\")\n",
    "print('[<h1> 태그의 컨텐트] ', bs.h1.text)\n",
    "print('[텍스트 형식으로 내용을 가지고 있는 <a> 태그의 컨텐트와 href 속성값] ',)\n",
    "aTag = bs.find_all('a')\n",
    "for tag in aTag:\n",
    "    if(tag.text.strip()):\n",
    "        print(tag.text, ' : ', tag['href'])\n",
    "print('[<img> 태그의 src 속성값] ',bs.img['src'])\n",
    "print('[첫 번째 <h2> 태그의 컨텐트] ',bs.h2.text)\n",
    "print('[<ul> 태그의 자식 태그들중 style 속성의 값이 green으로 끝나는 태그의 컨텐트] ',bs.ul.find(style=re.compile(\"green$\")).text)\n",
    "print('[두 번째 <h2> 태그의 컨텐트] ',bs.find_all('h2')[1].text)\n",
    "print('[<ol> 태그의 모든 자식 태그들의 컨텐트 ]')\n",
    "olTag = bs.find(\"ol\")\n",
    "olliTag = olTag.find_all(\"li\")\n",
    "for tag in olliTag:\n",
    "    print(tag.text)\n",
    "print('[<table> 태그의 모든 자손 태그들의 컨텐트 ]')\n",
    "print(bs.table.text.strip())\n",
    "tableTag = bs.table\n",
    "print('[name이라는 클래스 속성을 갖는 <tr> 태그의 컨텐트] ',tableTag.find(\"tr\", class_=\"name\").text)\n",
    "print('[target이라는 아이디 속성을 갖는 <td> 태그의 컨텐트] ',bs.find(\"td\", id='target').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1> 태그의 컨텐트]  HTML의 링크 태그\n",
      "[텍스트 형식으로 내용을 가지고 있는 <a> 태그의 컨텐트와 href 속성값] \n",
      "World Wide Consortium  :  http://www.w3.org/\n",
      "Java Page  :  http://java.sun.com/\n",
      "Python Page  :  http://www.python.org/\n",
      "Web Client 기술 학습  :  http://www.w3schools.com/\n",
      "[<img> 태그의 src 속성값]  http://unico2013.dothome.co.kr/image/duke.jpg\n",
      "[첫 번째 <h2> 태그의 컨텐트]  좋아하는 색\n",
      "[<ul> 태그의 자식 태그들중 style 속성의 값이 green으로 끝나는 태그의 컨텐트]  녹색\n",
      "[두] 번째 <h2> 태그의 컨텐트]  먹고싶은 음식\n",
      "[<ol> 태그의 모든 자식 태그들의 컨텐트 ]\n",
      "짜장면\n",
      "냉면\n",
      "돈까스\n",
      "갈비\n",
      "[<table> 태그의 모든 자손 태그들의 컨텐트 ]\n",
      "둘리또치도우너\n",
      "케라토사우루스타조외계인\n",
      "도봉구 쌍문동아프리카깐따삐아 별\n",
      "[name이라는 클래스 속성을 갖는 <tr> 태그의 컨텐트]  둘리또치도우너\n",
      "[target이라는 아이디 속성을 갖는 <td> 태그의 컨텐트]  아프리카\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/exercise_bs.html\" \n",
    "html = urllib.request.urlopen(url)\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "print('[<h1> 태그의 컨텐트] ', bs.select('h1')[0].text)\n",
    "print('[텍스트 형식으로 내용을 가지고 있는 <a> 태그의 컨텐트와 href 속성값] ',)\n",
    "aTag = bs.select('a')\n",
    "for tag in aTag:\n",
    "    if(tag.text.strip()):\n",
    "        print(tag.text, ' : ', tag['href'])\n",
    "print('[<img> 태그의 src 속성값] ',bs.select('img')[0]['src'])\n",
    "print('[첫 번째 <h2> 태그의 컨텐트] ',bs.select('h2:nth-of-type(1)')[0].text)\n",
    "print('[<ul> 태그의 자식 태그들중 style 속성의 값이 green으로 끝나는 태그의 컨텐트] ',bs.select('ul>li[style$=green]')[0].text)\n",
    "print('[두] 번째 <h2> 태그의 컨텐트] ',bs.select('h2:nth-of-type(2)')[0].text)\n",
    "print('[<ol> 태그의 모든 자식 태그들의 컨텐트 ]')\n",
    "olliTag = bs.select('ol>li')\n",
    "for tag in olliTag:\n",
    "    print(tag.text)\n",
    "print('[<table> 태그의 모든 자손 태그들의 컨텐트 ]')\n",
    "print(bs.select('table')[0].text.strip())\n",
    "print('[name이라는 클래스 속성을 갖는 <tr> 태그의 컨텐트] ',bs.select('tr.name')[0].text)\n",
    "print('[target이라는 아이디 속성을 갖는 <td> 태그의 컨텐트] ',bs.select('td#target')[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1> 태그의 콘텐츠] HTML의 링크 태그\n",
      "[텍스트 형식으로 내용을 가지고 있는 <a> 태그의 콘텐츠와 href 속성값]\n",
      "World Wide Consortium : http://www.w3.org/\n",
      "Java Page : http://java.sun.com/\n",
      "Python Page : http://www.python.org/\n",
      "Web Client 기술 학습 : http://www.w3schools.com/\n",
      "[<img> 태그의 src 속성값] http://unico2013.dothome.co.kr/image/duke.jpg\n",
      "[첫 번째 <h2> 태그의 콘텐츠] 좋아하는 색\n",
      "[<ul> 태그의 자식 태그들 중 style 속성의 값이 green으로 끝나는 태그의 콘텐츠]\n",
      "녹색\n",
      "[두 번째 <h2> 태그의 콘텐츠] 먹고싶은 음식\n",
      "[<ol> 태그의 모든 자식 태그들의 콘텐츠]\n",
      "짜장면\n",
      "냉면\n",
      "돈까스\n",
      "갈비\n",
      "[<table> 태그의 모든 자손 태그들의 콘텐츠]\n",
      "둘리또치도우너\n",
      "케라토사우루스타조외계인\n",
      "도봉구 쌍문동아프리카깐따삐아 별\n",
      "[name이라는 클래스 속성을 갖는 <tr> 태그의 콘텐츠] 둘리또치도우너\n",
      "[target이라는 아이디 속성을 갖는 <td> 태그의 콘텐츠] 아프리카\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/exercise_bs.html'\n",
    "r = requests.get(urlstr)\n",
    "r.encoding = 'utf-8'\n",
    "html_doc = r.text\n",
    "# print(html_doc)\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(\"[<h1> 태그의 콘텐츠]\", bs.find('h1').text)\n",
    "print(\"[텍스트 형식으로 내용을 가지고 있는 <a> 태그의 콘텐츠와 href 속성값]\")\n",
    "# atags = bs.find_all('a', len(text)>0)\n",
    "atags = bs.find_all('a')\n",
    "for atag in atags :\n",
    "    if atag.string != None :\n",
    "        print(atag.string, \":\", atag['href'])\n",
    "\n",
    "print(\"[<img> 태그의 src 속성값]\", bs.img['src'])\n",
    "print(\"[첫 번째 <h2> 태그의 콘텐츠]\", bs.h2.text)\n",
    "print(\"[<ul> 태그의 자식 태그들 중 style 속성의 값이 green으로 끝나는 태그의 콘텐츠]\")\n",
    "print(bs.find('ul').find_all('li', attrs={'style':re.compile(\"green$\")})[0].text )\n",
    "print(\"[두 번째 <h2> 태그의 콘텐츠]\", bs.find_all('h2')[1].text)\n",
    "print(\"[<ol> 태그의 모든 자식 태그들의 콘텐츠]\")\n",
    "for tg in bs.find('ol').find_all('li') :\n",
    "    print (tg.text)\n",
    "print(\"[<table> 태그의 모든 자손 태그들의 콘텐츠]\")\n",
    "for tg in bs.find('table').find_all('tr') :\n",
    "    print (tg.text)\n",
    "print(\"[name이라는 클래스 속성을 갖는 <tr> 태그의 콘텐츠]\", bs.find('tr', class_=\"name\").text)\n",
    "print(\"[target이라는 아이디 속성을 갖는 <td> 태그의 콘텐츠]\", bs.find('td', id='target').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스제목--------------\n",
      "['[단독] \"QR코드 보여달라\"는 포차 직원 급소 걷어찬 20대女', '호주 남성, 공원서 점심 먹다가 까치에게 두 눈 쪼여', '검찰 \"동양대 표창장 위조 30초면 된다\"..법정서 직접 시연', '\"기자가 출근방해\"..사진 찍어 SNS 올린 추미애', \"LA 상공에 다시 나타난 '아이언맨'..조종사들 증언 잇따라\", \"'드디어 흔들리나'..마이너스 전환에 매물 쌓이기 시작한 강남\", \"시중에 풀린 돈 3100조 '사상 최대'..부동산·증시 거품 우려\", '국민의힘 \"서울·부산시장 \\'시민후보\\'로\"..\\'미스터트롯\\' 경선 준비(종합)', '지적장애 딸 성폭행하고 \"돌볼 사람없다\"며 선처 호소한 아빠', \"'따상' 갔던 빅히트 미끄러지자..엔터株 '와르르'\", \"'거짓 미투' 피해 박진성 시인 극단 선택 암시하고 잠적\", '공중급유기로 미국 간 서욱에.. 홍준표 \"장관 자가용이냐\"', '장윤정 \"3년 전 이혼 후 중학생·고3 두 딸과 살고 있다\"(\\'같이 삽시다\\')[종합]', \"검찰이 덮은 김기현 전 울산시장 동생의 '자백'\", \"보건교사 '심상정'이 국회에서 무지개칼을 휘두른 이유\", '\\'골목식당\\' 최고 시청률 불러온 백종원 분노 \"장사 너무 심하게 한다\"', '[단독]\"계약 끝나니 16억 내고 사라\"..3679 임대가구 발동동', '\"김양식장에 사용하려고\" 무기산 3만리터 산속 보관한 50대', \"'골목', 백종원은 왜 먹어보지도 않고 싫다고 했을까\", '11일간 먹지도 자지도 않고 날아간 흑꼬리도요 신기록 세웠다(종합)', '국가비 처벌받나..\"격리중 지인초대는 의무 위반, 지자체 조사\"', '\"걸그룹 시켜줄게\" 미성년자 꼬드겨 음란행위 치과의사 징역 7년', '[D:방송 뷰] 싹쓰리에는 냉철했던 시선, 환불원정대는 다르다?', \"[2020 BBMAs] 방탄소년단, 왜 인천공항서 '다이너마이트' 선보였나\", \"'코로나19 전쟁'서 승리했다더니..中서 돌아온 대만인 확진\", \"'故 구하라 협박·폭행' 최종범 징역 1년 확정..불법촬영은 결국 무죄\", '진중권에 맞선 與 부대변인에 시선..\"재담꾼 정치혐오 부추겨\"', '김승현 \\'불새2020\\'으로 연기자 복귀 \"최선 다할 것\"(공식)', '\"부르면 나간다\"는 한동훈 증인채택 놓고 국감장 곳곳 설전', \"박정수 '카메라가 반갑지 않는 눈빛'[포토엔HD]\", '\"어느 시대냐\" 日정부, 나카소네 전 총리 장례때 국립대 조기 게양, 묵념 요구 논란', '\\'장예원 동생\\' 장예인 아나, 결혼발표 \"소규모 예식..예쁘게 살게요\"', '서민 교수 \"대깨문 압력에 지방강의 취소돼, 대깨문의 나라\"', '반년 만에 하늘길 뚫린 김해공항 국제선..첫날 승객들 \"다행이에요\"', \"'빌런의 반격' 휴스턴, 탬파베이에 승리..최지만 1안타 [ALCS4]\", '\"펭수·뿡뿡이·보니하니 죄다 뺏겼습니다\"..EBS 자회사 \\'눈물\\'', '보이스피싱에 속아 3000만원 갖고 부산 온 60대, 경찰이 예방', '대규모 확진 부산요양병원 사망 2명으로 늘어..추가 확진은 없어(종합)', '경비행기 추락사고서 엄마 품에 안긴 한살 아기만 살았다(종합)', \"개와 늑대의 잡종 '늑대개' 위험천만..미 2살배기 한쪽 팔 잃어\", '[단독]\"육아스트레스로..\" 2개월 아이 던져 숨지게 한 20대 아빠', '미스코리아 장윤정 \"3년 전 이혼 후 정신없이 살았다\" (\\'같이 삽시다\\') [엑\\'s 리뷰]', '추신수 떠난 텍사스, 김하성 영입 후보 \"강정호보다 낫다\"', \"[단독] 박휘순♥17세 연하 예비신부, '아내의맛' 합류..결혼식 공개할까\", '[단독] 75년된 구식 무기로 예비군 훈련.. 장비 노후화 심각', '정년퇴직 3년 앞두고 낡은 시골학교를 벽화로 채운 미술 선생님', '사이클링히트 노리던 시거, 5회에 교체한 로버츠 감독 왜?', '해뜨락요양병원 확진자 1명 숨져..병원종사자 접촉 103명', '고 콜레스테롤에 의한 대장암 전이 과정 밝혀졌다', \"소금으로 '생태계 파괴자' 칡덩굴 없앤다..고사율 70.2%\"]\n",
      "50\n",
      "뉴스이름--------------\n",
      "['중앙일보', '연합뉴스', '연합뉴스', '연합뉴스', '연합뉴스', '연합뉴스', '뉴시스', '뉴스1', '뉴스1', '뉴스1', '서울신문', '한국일보', 'OSEN', '뉴스타파', '뉴스1', '뉴스엔', '국민일보', '뉴스1', '엔터미디어', '연합뉴스', '연합뉴스', '뉴스1', '데일리안', 'YTN', '헤럴드경제', '뉴스1', '연합뉴스', '뉴스엔', '연합뉴스', '뉴스엔', '중앙일보', '뉴스1', '한국일보', '뉴스1', 'MK스포츠', '한국경제', '뉴시스', '연합뉴스', '연합뉴스', '연합뉴스', '노컷뉴스', '엑스포츠뉴스', 'OSEN', '스포츠동아', '세계일보', '연합뉴스', 'OSEN', '뉴스1', '뉴스1', '연합뉴스']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "title = []\n",
    "name = []\n",
    "urlstr = 'http://media.daum.net/ranking/popular/'\n",
    "r = requests.get(urlstr)\n",
    "r.encoding = \"utf-8\"\n",
    "bs = BeautifulSoup(r.text, 'html.parser')\n",
    "titleList = bs.select('.rank_news>ul>li>.cont_thumb>strong>a')\n",
    "nameList = bs.select('div.cont_thumb > strong > span')\n",
    "\n",
    "for titleDom in titleList:\n",
    "\ttitle.append(titleDom.string)\n",
    "for nameDom in nameList:\n",
    "\tname.append(nameDom.string)\n",
    "\n",
    "print('뉴스제목--------------')\n",
    "print(title)\n",
    "print(len(title))\n",
    "\n",
    "print('뉴스이름--------------')\n",
    "print(name)\n",
    "print(len(name))\n",
    "\n",
    "with open('C:/Temp/news.csv', \"wt\", encoding=\"utf-8\") as f:\n",
    "    f.write('newstitle,newscomname\\n')  \n",
    "    for i in range(len(title)):\n",
    "        f.write('\"'+title[i]+'\",'+name[i]+'\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "n = 1\n",
    "while True:\n",
    "    req = requests.get('https://movie.daum.net/moviedb/grade?movieId=131704&type=netizen&page='+str(n))\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    points = soup.select('div.raking_grade > em')\n",
    "    reviews = soup.select('div.main_detail > ul > li > div > p')\n",
    "    if len(points) == 0 :\n",
    "        break\n",
    "\n",
    "    movie_point = []\n",
    "    movie_review = [] \n",
    "\n",
    "    for dom in points:\n",
    "        movie_point.append(dom.text)\n",
    "\n",
    "    for dom in reviews:\n",
    "        content=dom.text.strip()\n",
    "        content=re.sub(\"[\\n\\t]\", ' ', content)\n",
    "        movie_review.append(content)\n",
    "\n",
    "        \n",
    "    commentLength = len(movie_point)   \n",
    "    for i in range(commentLength):\n",
    "        print(movie_point[i] + \",\"+movie_review[i]) \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수버전\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "def naver_search (keyword, callType = 'JSON') :\n",
    "    client_key = 'izGsqP2exeThwwEUVU3x'\n",
    "    client_secret = 'WrwbQ1l6ZI'\n",
    "    query = keyword\n",
    "\n",
    "    encText = urllib.parse.quote_plus(query)\n",
    "    num = 5\n",
    "    if callType == 'JSON' :\n",
    "        urlhead = 'https://openapi.naver.com/v1/search/local.json?query='\n",
    "    elif callType == 'XML' :\n",
    "        urlhead = 'https://openapi.naver.com/v1/search/local.xml?query='\n",
    "    else :\n",
    "        print('JSON or XML only')\n",
    "        return   \n",
    "\n",
    "    naver_url = urlhead + encText + '&display=' + str(num)\n",
    "    request = urllib.request.Request(naver_url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode() \n",
    "\n",
    "    if(rescode == 200):\n",
    "        response_body = response.read()\n",
    "        count = 1     \n",
    "        if callType == 'JSON' :\n",
    "            dataList = json.loads(response_body)\n",
    "            print('[' + query + '집에 대한 네이버 지역 정보(JSON)]')\n",
    "            for data in dataList['items'] :\n",
    "                print (str(count) + ' : ' + data['title'] + ',' + data['telephone'] + ',' + data['address'])\n",
    "                count += 1\n",
    "\n",
    "        elif callType == 'XML' :\n",
    "            xmlsoup = BeautifulSoup(response_body, 'xml')\n",
    "            items = xmlsoup.find_all('item')\n",
    "            print('[' + query + '집에 대한 네이버 지역 정보(XML)]')\n",
    "            for data in items:\n",
    "                print (str(count) + ' : ' + data.title.string + ',' +\n",
    "                       ('없음' if data.telephone.string == None else data.telephone.string) + \n",
    "                       ',' + data.address.string)\n",
    "                count += 1\n",
    "    else:\n",
    "        print('오류 코드 : ' + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[짜장면집에 대한 네이버 지역 정보(XML)]\n",
      "1 : 란주라미엔,없음,서울특별시 중구 충무로1가 25-14\n",
      "2 : 개화,없음,서울특별시 중구 명동2가 107-1\n",
      "3 : 원흥,없음,서울특별시 중구 다동 92\n",
      "4 : 일품향,없음,서울특별시 중구 명동2가 105\n",
      "5 : 더 플라자 도원,없음,서울특별시 중구 태평로2가 23\n"
     ]
    }
   ],
   "source": [
    "naver_search('짜장면', 'XML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[쌀국수집에 대한 네이버 지역 정보(JSON)]\n",
      "1 : 호아빈 서울시청점,,서울특별시 중구 서소문동 14-2\n",
      "2 : 포리엔,,서울특별시 중구 소공동 85-2\n",
      "3 : 72420,,서울특별시 동작구 사당동 1039-16\n",
      "4 : 레호이 소월길 본점,,서울특별시 용산구 이태원동 261-9\n",
      "5 : 에머이 종로1호점(본점),,서울특별시 종로구 관철동 16-9\n"
     ]
    }
   ],
   "source": [
    "naver_search('쌀국수', 'JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[쌀국수집에 대한 네이버 지역 정보(XML)]\n",
      "1 : 호아빈 서울시청점,없음,서울특별시 중구 서소문동 14-2\n",
      "2 : 포리엔,없음,서울특별시 중구 소공동 85-2\n",
      "3 : 72420,없음,서울특별시 동작구 사당동 1039-16\n",
      "4 : 레호이 소월길 본점,없음,서울특별시 용산구 이태원동 261-9\n",
      "5 : 에머이 종로1호점(본점),없음,서울특별시 종로구 관철동 16-9\n"
     ]
    }
   ],
   "source": [
    "# XML버전\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "client_key = 'izGsqP2exeThwwEUVU3x'\n",
    "client_secret = 'WrwbQ1l6ZI'\n",
    "query = '쌀국수'\n",
    "encText = urllib.parse.quote_plus(query)\n",
    "num = 5\n",
    "naver_url = 'https://openapi.naver.com/v1/search/local.xml?query=' + encText + '&display=' + str(num)\n",
    "request = urllib.request.Request(naver_url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "\n",
    "if(rescode == 200):\n",
    "    response_body = response.read()\n",
    "    xmlsoup = BeautifulSoup(response_body, 'xml')\n",
    "    items = xmlsoup.find_all('item')\n",
    "    count = 1\n",
    "    print('[' + query + '집에 대한 네이버 지역 정보(XML)]')\n",
    "    for data in items:\n",
    "        print (str(count) + ' : ' + data.title.string + ',' + ('없음' if data.telephone.string == None else data.telephone.string) + ',' + data.address.string)\n",
    "        count += 1\n",
    "else:\n",
    "    print('오류 코드 : ' + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[쌀국수집에 대한 네이버 지역 정보(JSON)]\n",
      "1 : 호아빈 서울시청점,,서울특별시 중구 서소문동 14-2\n",
      "2 : 포리엔,,서울특별시 중구 소공동 85-2\n",
      "3 : 72420,,서울특별시 동작구 사당동 1039-16\n",
      "4 : 레호이 소월길 본점,,서울특별시 용산구 이태원동 261-9\n",
      "5 : 에머이 종로1호점(본점),,서울특별시 종로구 관철동 16-9\n"
     ]
    }
   ],
   "source": [
    "# JSON 버전\n",
    "import urllib.request\n",
    "import json\n",
    "client_key = 'izGsqP2exeThwwEUVU3x'\n",
    "client_secret = 'WrwbQ1l6ZI'\n",
    "query = '쌀국수'\n",
    "encText = urllib.parse.quote_plus(query)\n",
    "num = 5\n",
    "naver_url = 'https://openapi.naver.com/v1/search/local.json?query=' + encText + '&display=' + str(num)\n",
    "request = urllib.request.Request(naver_url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "\n",
    "if(rescode == 200):\n",
    "    response_body = response.read()\n",
    "    dataList = json.loads(response_body)\n",
    "    count = 1\n",
    "    print('[' + query + '집에 대한 네이버 지역 정보(JSON)]')\n",
    "    for data in dataList['items'] :\n",
    "        print (str(count) + ' : ' + data['title'] + ',' + data['telephone'] + ',' + data['address'])\n",
    "        count += 1\n",
    "else:\n",
    "    print('오류 코드 : ' + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list를 사용하여 Series 만들기\n",
    "data = [10, 20, 30, 40, 50]\n",
    "series = pd.Series(data)\n",
    "print(type(series)) \n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#직접 index 를 부여해보기 \n",
    "data2 = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5}\n",
    "series2 = pd.Series(data2)\n",
    "print(type(series)) \n",
    "print(series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#직접 index 를 부여해보기 \n",
    "data2 = {'학생1':'둘리', '학생2':'또치', '학생3':'도우너', '학생4':'희동이', '학생5':'마이콜'}\n",
    "series2 = pd.Series(data2)\n",
    "print(type(series)) \n",
    "print(series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#직접 index 를 부여해보기 \n",
    "data2 = ['둘리', '또치', '도우너', '희동이', '마이콜']\n",
    "series2 = pd.Series(data2, index=['학생1','학생2','학생3','학생4','학생5'])\n",
    "print(type(series)) \n",
    "print(series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood = ['A형', 'B형', 'O형', 'AB형']\n",
    "st = [34.2, 27.1, 26.7, 11.5]\n",
    "sr = pd.Series(st, index=blood)\n",
    "print(\"[시리즈 sr 출력]\")\n",
    "print(sr)\n",
    "print(\"[시리즈 sr에서 인덱싱과 슬라이싱하여 출력(숫자인덱스 사용)]\")\n",
    "print(sr[0])\n",
    "print(sr[-1])\n",
    "print(sr[1])\n",
    "print(sr[1:4])\n",
    "print(\"[시리즈 sr에서 인덱싱과 슬라이싱하여 출력(이름인덱스 사용)]\")\n",
    "print(sr['A형'])\n",
    "print(sr['AB형'])\n",
    "print(sr['B형'])\n",
    "print(sr['B형':'AB형'])\n",
    "print(\"[시리즈 sr의 크기 출력 ]\")\n",
    "print(len(sr))\n",
    "print(\"[시리즈 sr의 인덱스 출력 ]\")\n",
    "print(sr.index)\n",
    "print(\"[시리즈 sr의 데이터 값 출력 ]\")\n",
    "print(sr.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name':['둘리', '또치', '도우너', '희동이'],\n",
    "    'kor':[90, 80, 70, 70],\n",
    "    'eng':[99, 98, 97, 46],\n",
    "    'mat':[90, 70, 70, 60],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"타입 : \", type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name':['둘리', '또치', '도우너', '희동이'],\n",
    "    'kor':[90, 80, 70, 70],\n",
    "    'eng':[99, 98, 97, 46],\n",
    "    'mat':[90, 70, 70, 60],\n",
    "}\n",
    "df = pd.DataFrame(data, index=['학생1','학생2','학생3','학생4'])\n",
    "print(\"타입 : \", type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name':['둘리', '또치', '도우너', '희동이'],\n",
    "    'kor':[90, 80, 70, 70],\n",
    "    'eng':[99, 98, 97, 46],\n",
    "    'mat':[90, 70, 70, 60],\n",
    "}\n",
    "df = pd.DataFrame(data, index=['학생1','학생2','학생3','학생4'])\n",
    "df.index = ['st1', 'st2', 'st3', 'st4']\n",
    "df.columns = ['dooly', 'doochi', 'dounar', 'heedong']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name':['듀크1', '듀크2', '듀크3', '듀크4', '듀크5', '듀크6', '듀크7'],\n",
    "    'kor':[90, 80, 70, 70, 60, 70, 90],\n",
    "    'eng':[99, 98, 97, 46, 77, 56, 90],\n",
    "    'mat':[90, 70, 70, 60, 88, 99, 90],\n",
    "}\n",
    " \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print( df.head() ) #앞의 다섯명에 대한 데이터만 나온다. \n",
    "print( df.tail() )\n",
    "print( df.columns)\n",
    "print( df['name'])\n",
    "print( df.eng) \n",
    "print( df[['kor', 'mat']]) \n",
    "#iloc 함수 : 배열에서의 위치값으로 데이터를 접근 할 수 있다. \n",
    "print(\"iloc 함수 사용 -----------\")\n",
    "print( df.iloc[3])\n",
    "print( df.iloc[0,0]) #0,0번에 해당하는 데이터 출력하기 \n",
    "print( df.iloc[3,2]) #3번째 행의 2번째 열 \n",
    "print( df.iloc[2:4,2])\n",
    "print( df.iloc[2:4,2:4])\n",
    "\n",
    "print(\"loc함수 사용 -------------\")\n",
    "#loc 함수는 필드명으로 데이터를 출력할 수 있다 .\n",
    "print( df.loc[3])\n",
    "print( df.loc[0, 'name']) #0번째 행의 name필드 값 출력 \n",
    "print( df.loc[3, 'eng']) #0번째 행의 name필드 값 출력 \n",
    "print( df.loc[2:3, 'eng'])\n",
    "print( df.loc[2:3, 'eng':'mat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('name', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1번\n",
    "data = {\n",
    "    'name':['둘리', '또치', '도우너', '희동이'],\n",
    "    'kor':[90, 80, 70, 70],\n",
    "    'eng':[99, 98, 97, 46],\n",
    "    'mat':[90, 70, 70, 60],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['class'] = ['1반', '2반', '1반', '2반']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[4] = ['마이콜', 80,80,80,'1반']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name':['둘리', '또치', '도우너', '희동이'],\n",
    "    'kor':[90, 80, 70, 70],\n",
    "    'eng':[99, 98, 97, 46],\n",
    "    'mat':[90, 70, 70, 60],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['class'] = ['1반', '2반', '1반', '2반']\n",
    "df.loc[4] = ['마이콜', 80,80,80,'1반']\n",
    "df.set_index('name', inplace=True)\n",
    "df.columns = ['국어', '영어', '수학', '반번호']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['마이콜', ['국어', '영어', '수학']] = 100\n",
    "#df.loc['마이콜'] = 100\n",
    "df.loc['희동이', '영어'] = 90\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "print(df)\n",
    "df.rename(columns={'name':'성명'}, inplace=True )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sort_values(by='국어', ascending=False)\n",
    "print(df1)\n",
    "df2 = df.sort_values(by='영어')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['총점'] = df['국어']+df['수학']+df['영어']\n",
    "df.sort_values(by='총점', ascending=False, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.drop('반번호', axis=1)\n",
    "print(df3)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.drop(4)\n",
    "print(df4)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {'kor':90, 'mat':80}\n",
    "data2 = {'kor':90, 'eng':70}\n",
    "data3 = {'kor':90, 'eng':70, 'mat':80}\n",
    "\n",
    "series1 = pd.Series( data1 )\n",
    "series2 = pd.Series( data2 )\n",
    "series3 = pd.Series( data3 )\n",
    "result = series1 + series2 + series3\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {'kor':90, 'mat':80}\n",
    "data2 = {'kor':90, 'eng':70}\n",
    "data3 = {'kor':90, 'eng':70, 'mat':80}\n",
    "\n",
    "series1 = pd.Series( data1 )\n",
    "series2 = pd.Series( data2 )\n",
    "series3 = pd.Series( data3 )\n",
    "result = series1.add(series2, fill_value=0) \n",
    "result = result.add(series3, fill_value=0) \n",
    "#result =        + series3\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11번\n",
    "import pandas as pd\n",
    " \n",
    "data = {\n",
    "    'X1':[2.9, 2.4, 2, 2.3, 3.2],\n",
    "    'X2':[9.2, 8.7, 7.2, 8.5, 9.6],\n",
    "    'X3':[13.2, 11.5, 10.8, 12.3, 12.6],\n",
    "    'X4':[2, 3, 4, 3, 2]\n",
    "}\n",
    " \n",
    "df = pd.DataFrame(data, index=['Y1','Y2','Y3', 'Y4', 'Y5'])\n",
    "print(df)\n",
    "df.loc['Y6']=[10, 20, 30, 40]\n",
    "print(df)\n",
    "df = df + 10\n",
    "print(df)\n",
    "df['total'] = df.X1 +  df.X2 + df.X3 + df.X4\n",
    "print(df)\n",
    "print(df.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/score.csv\")\n",
    "\n",
    "print(\"컬럼명 : \", data.columns)\n",
    "print(\"인덱스 : \", data.index)\n",
    "\n",
    "#총점, 평균 구하기 \n",
    "data['total'] = data['kor'] + data['eng']+data['mat']\n",
    "data['avg'] = round(data['total']/3,2)\n",
    "\n",
    "display( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/score_noheader.csv\", header=None)\n",
    "display(data)\n",
    "\n",
    "print(\"컬럼명 : \", data.columns)\n",
    "print(\"인덱스 : \", data.index)\n",
    "\n",
    "print(\"컬럼명 추가 ----------\")\n",
    "data.columns = ['name', 'kor', 'eng', 'mat']\n",
    "print(\"컬럼명 : \", data.columns)\n",
    "display(data)\n",
    "\n",
    "print(\"total과 avg열 추가 -------\")\n",
    "#총점, 평균 구하기 \n",
    "data['total'] = data['kor'] + data['eng']+data['mat']\n",
    "data['avg'] = round(data['total']/3,2)\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/score_header.csv\", header=3)\n",
    "display(data)\n",
    "\n",
    "print(\"컬럼명 : \", data.columns)\n",
    "print(\"인덱스 : \", data.index)\n",
    "\n",
    "#총점, 평균 구하기 \n",
    "data['total'] = data['kor'] + data['eng']+data['mat']\n",
    "data['avg'] = round(data['total']/3,2)\n",
    "\n",
    "data.to_csv(\"c:/Temp/score_result.csv\",  header=False, mode='a', index=False)\n",
    "display( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"./data/score.xlsx\")\n",
    "display(data)\n",
    "data['total'] = data['kor'] + data['eng']+data['mat']\n",
    "data['avg'] = round(data['total']/3,2)\n",
    "data.sort_values(by='avg', ascending=False, inplace=True)\n",
    "display(data)\n",
    "data.to_excel(\"c:/Temp/score_result1.xlsx\")\n",
    "data.to_excel(\"c:/Temp/score_result2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"data/mydata.json\")\n",
    "print(\"기본정보 보기\") \n",
    "print(data.info())\n",
    "print(\"앞에서 부터 5개만 미리 보기\") \n",
    "display( data.head() )\n",
    "\n",
    "print(\"뒤에서 부터 5개만 미리 보기\") \n",
    "display( data.tail() )\n",
    "\n",
    "print(\"앞에서 부터 10개만 미리 보기\") \n",
    "display( data.head(10))\n",
    "#데이터프레임의 차원 행, 열의 개수 확인 가능 \n",
    "print( data.shape )\n",
    "\n",
    "row, col = data.shape  \n",
    "#tuple타입임, 행과 열에 대한 정보를 모두 가지고 있음\n",
    "print(\"행의 개수 : \", row, \", 열의 개수 : \", col, sep = \"\")\n",
    "data.to_csv(\"c:/Temp/mydata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "data = pd.read_csv(\"./data/mpgdata.csv\")\n",
    "\n",
    "print(\"앞에서 부터 3개만 미리 보기\") \n",
    "display( data.head(3))\n",
    "#데이터프레임의 차원 행, 열의 개수 확인 가능 \n",
    "print( data.shape )\n",
    "\n",
    "row, col = data.shape  \n",
    "#tuple타입임, 행과 열에 대한 정보를 모두 가지고 있음\n",
    "print(\"행의 개수 \", row)\n",
    "print(\"열의 개수 \", col)\n",
    "print(\"기술통계 정보 요약\") \n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            newstitle newscomname\n",
      "0    김진숙, 문 대통령에 편지 \"옛 동지가 묻는다..언제까지 약자가 약자를 응원해야 하나\"        경향신문\n",
      "1              [단독]\"머리 감기는데 가슴을..\" 요양보호사 42%가 성희롱 당했다       머니투데이\n",
      "2              이인영, 노벨평화상 수상 WFP에 \"선정 축하..北 사업 적극 지원\"         뉴스1\n",
      "3                       '사상초유' 검찰총장까지 수사 받나..이성윤에 달렸다         뉴시스\n",
      "4              [단독]로젠택배 40대 기사, '갑질' 호소 유서 남기고 극단적 선택         뉴스1\n",
      "5              100kg 넘는 아들 목 졸라 살해한 76세 노모에 징역 20년 구형        연합뉴스\n",
      "6                 뭘 먹었길래..중국 14살짜리 중학생 키가 무려 '2m21cm'        연합뉴스\n",
      "7            '국민의짐' 표현 \"사과하라\"..이재명 \"국민의짐 진짜 안 되길 바란다\"         뉴시스\n",
      "8                   \"추미애, 정치적 목적의 윤석열 망신주기\"..법조계 한목소리         뉴스1\n",
      "9               \"외국인 건보혜택 중국인이 71% 차지..5년반 동안 2조4천억원\"        연합뉴스\n",
      "10    [단독] \"불투명 비말 칸막이 때문에 칠판이 안 보여요\".. 초등학교 '깜깜이 수업'        서울신문\n",
      "11            고창서 독감백신 맞은 70대 이튿날 사망..\"인과관계 확인 중\"(종합)        연합뉴스\n",
      "12                  방금전 방송에서 나온 제품이 바로 홈쇼핑에..우연이 아니었다       머니투데이\n",
      "13         \"절도 이력 때문에 해사 불합격\"..법원, 신원조회 위법 \"불합격 취소하라\"        중앙일보\n",
      "14                      코로나에 다 망했다는데..'빵집'만 살아남은 이유는?       헤럴드경제\n",
      "15                  소형 전기밥솥, 보온 기능에 차이..밥 딱딱하게 굳는 제품도         뉴스1\n",
      "16                \"어려운 이웃에게 써달라\" 대전 도마2동에 100만원 익명 기부        연합뉴스\n",
      "17          1억 마세라티·5천 벤츠 몰며 서울 공공임대주택 거주 어떻게 가능?(종합)         뉴시스\n",
      "18            21세 男 1명 1년간 3062회 병원 이용 최다..건보 3천만원 소요         뉴시스\n",
      "19                 국민의힘 \"조국 딸 입학 취소 왜 안 하나\" 부산대 국감 공세        연합뉴스\n",
      "20                 30대 남성의 수상한 기록, 2년여간 식욕억제제 2만정 타갔다       머니투데이\n",
      "21               손흥민 토트넘 잔류시 최고 주급 유력..EPL 톱5 진입 가능성도      스포티비뉴스\n",
      "22                                '콩다방' 커피빈마저 매물로 나왔다       머니투데이\n",
      "23     '10조 빅딜' 이끈 최태원 SK회장의 승부수.. 현상유지만 하는 다른 그룹과 대조        조선비즈\n",
      "24                    전문직 소득 중 의사가 압도적 1위..변호사와 2배 격차        서울신문\n",
      "25                    [단독] 고창서 70대 여성 독감 백신 접종 후 또 사망         더팩트\n",
      "26             '불청' 김홍표 \"교통사고로 4번 대수술, 일용직 조경에 대리운전도\"         뉴스엔\n",
      "27                  환자 저항에 검사하던 보건소 직원 옷 찢어져 '확진'(종합)         뉴시스\n",
      "28                   [단독] 참모들 부른 尹 \"라임 비호세력 처단\" 직접 썼다        국민일보\n",
      "29              秋가 때리면 커지는 윤석열 존재감..'가족 수사' 이번엔 다를 수도         뉴스1\n",
      "30      '노는 언니' 박세리 \"잘생긴 남자만 만났다\" 10년지기 골프 후배들 폭로에 한탄         뉴스엔\n",
      "31                           토트넘 '날벼락'..레알 레길론 재영입 고려      스포티비뉴스\n",
      "32               [예천 육상] \"누구야?!\" 슈퍼유망주 '초미네이터' 등장에 흥분        에스티엔\n",
      "33                   '정경심 안대 퍼포먼스' 5명, 검찰송치..모욕 혐의 적용         뉴시스\n",
      "34              \"밥 굶는 아이 없도록\"..전주 '엄마의 밥상'에 6년간 8억 쇄도        연합뉴스\n",
      "35                            전국노래자랑 현장에서 포착한 대한민국 초상        연합뉴스\n",
      "36                      \"강원랜드 20초만에 털려..열쇠 분실 6년간 몰라\"        서울신문\n",
      "37           [현장연결] 질병청 \"코로나 발생 안정세..이제 1단계 성적표 나올 것\"      연합뉴스TV\n",
      "38            손흥민, \"영어 못하는 느낌 아니까\".. '신입' 비니시우스 돕는 이유      스포탈코리아\n",
      "39               '러시아 미녀' 라자레바, 차원이 다른 대박 외인..한국 왜 왔니        OSEN\n",
      "40              음주운전 사고부담금 최대 1억6500만원..전동킥보드도 차보험 보상       아시아경제\n",
      "41             '감사원 발표에 한숨' 월성원전 주민들 \"경제성 없다는 이유 밝혀라\"         뉴스1\n",
      "42  [단독] '밥심' 박해미 \"전남편 음주사건 심경 고백 후련, 子 황성재 고마워 눈물...      엑스포츠뉴스\n",
      "43                         \"야당답지 못하다\"..野원로들, 김종인에 쓴소리       헤럴드경제\n",
      "44                         무리한 탈원전 정책에 무너진 韓 '원전 생태계'        조선비즈\n",
      "45      이혜리 \"'응팔' 5년만 박보검과 재회, 간식까지 챙겨줘 든든+감사\"[직격인터뷰]         뉴스엔\n",
      "46                \"확진자 쏟아지는 부산 북구에 차마\"..순천시,구상권 청구 보류         뉴스1\n",
      "47                    편의점 털려던 강도, 가게 갇혀 검거..종업원이 문 막아        동아일보\n",
      "48                 27m길이 명나라 그림 850억원에 낙찰..중국 고서화 최고가        연합뉴스\n",
      "49                  양주지역 정치인들, 투병생활 '이성호 시장' 자진 퇴진 촉구         뉴시스\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newstitle</th>\n",
       "      <th>newscomname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>김진숙, 문 대통령에 편지 \"옛 동지가 묻는다..언제까지 약자가 약자를 응원해야 하나\"</td>\n",
       "      <td>경향신문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[단독]\"머리 감기는데 가슴을..\" 요양보호사 42%가 성희롱 당했다</td>\n",
       "      <td>머니투데이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이인영, 노벨평화상 수상 WFP에 \"선정 축하..北 사업 적극 지원\"</td>\n",
       "      <td>뉴스1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'사상초유' 검찰총장까지 수사 받나..이성윤에 달렸다</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[단독]로젠택배 40대 기사, '갑질' 호소 유서 남기고 극단적 선택</td>\n",
       "      <td>뉴스1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100kg 넘는 아들 목 졸라 살해한 76세 노모에 징역 20년 구형</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>뭘 먹었길래..중국 14살짜리 중학생 키가 무려 '2m21cm'</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'국민의짐' 표현 \"사과하라\"..이재명 \"국민의짐 진짜 안 되길 바란다\"</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"추미애, 정치적 목적의 윤석열 망신주기\"..법조계 한목소리</td>\n",
       "      <td>뉴스1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"외국인 건보혜택 중국인이 71% 차지..5년반 동안 2조4천억원\"</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[단독] \"불투명 비말 칸막이 때문에 칠판이 안 보여요\".. 초등학교 '깜깜이 수업'</td>\n",
       "      <td>서울신문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>고창서 독감백신 맞은 70대 이튿날 사망..\"인과관계 확인 중\"(종합)</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>방금전 방송에서 나온 제품이 바로 홈쇼핑에..우연이 아니었다</td>\n",
       "      <td>머니투데이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"절도 이력 때문에 해사 불합격\"..법원, 신원조회 위법 \"불합격 취소하라\"</td>\n",
       "      <td>중앙일보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>코로나에 다 망했다는데..'빵집'만 살아남은 이유는?</td>\n",
       "      <td>헤럴드경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>소형 전기밥솥, 보온 기능에 차이..밥 딱딱하게 굳는 제품도</td>\n",
       "      <td>뉴스1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"어려운 이웃에게 써달라\" 대전 도마2동에 100만원 익명 기부</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1억 마세라티·5천 벤츠 몰며 서울 공공임대주택 거주 어떻게 가능?(종합)</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21세 男 1명 1년간 3062회 병원 이용 최다..건보 3천만원 소요</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>국민의힘 \"조국 딸 입학 취소 왜 안 하나\" 부산대 국감 공세</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30대 남성의 수상한 기록, 2년여간 식욕억제제 2만정 타갔다</td>\n",
       "      <td>머니투데이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>손흥민 토트넘 잔류시 최고 주급 유력..EPL 톱5 진입 가능성도</td>\n",
       "      <td>스포티비뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'콩다방' 커피빈마저 매물로 나왔다</td>\n",
       "      <td>머니투데이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'10조 빅딜' 이끈 최태원 SK회장의 승부수.. 현상유지만 하는 다른 그룹과 대조</td>\n",
       "      <td>조선비즈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>전문직 소득 중 의사가 압도적 1위..변호사와 2배 격차</td>\n",
       "      <td>서울신문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[단독] 고창서 70대 여성 독감 백신 접종 후 또 사망</td>\n",
       "      <td>더팩트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'불청' 김홍표 \"교통사고로 4번 대수술, 일용직 조경에 대리운전도\"</td>\n",
       "      <td>뉴스엔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>환자 저항에 검사하던 보건소 직원 옷 찢어져 '확진'(종합)</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[단독] 참모들 부른 尹 \"라임 비호세력 처단\" 직접 썼다</td>\n",
       "      <td>국민일보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>秋가 때리면 커지는 윤석열 존재감..'가족 수사' 이번엔 다를 수도</td>\n",
       "      <td>뉴스1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>'노는 언니' 박세리 \"잘생긴 남자만 만났다\" 10년지기 골프 후배들 폭로에 한탄</td>\n",
       "      <td>뉴스엔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>토트넘 '날벼락'..레알 레길론 재영입 고려</td>\n",
       "      <td>스포티비뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[예천 육상] \"누구야?!\" 슈퍼유망주 '초미네이터' 등장에 흥분</td>\n",
       "      <td>에스티엔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>'정경심 안대 퍼포먼스' 5명, 검찰송치..모욕 혐의 적용</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\"밥 굶는 아이 없도록\"..전주 '엄마의 밥상'에 6년간 8억 쇄도</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>전국노래자랑 현장에서 포착한 대한민국 초상</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\"강원랜드 20초만에 털려..열쇠 분실 6년간 몰라\"</td>\n",
       "      <td>서울신문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[현장연결] 질병청 \"코로나 발생 안정세..이제 1단계 성적표 나올 것\"</td>\n",
       "      <td>연합뉴스TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>손흥민, \"영어 못하는 느낌 아니까\".. '신입' 비니시우스 돕는 이유</td>\n",
       "      <td>스포탈코리아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>'러시아 미녀' 라자레바, 차원이 다른 대박 외인..한국 왜 왔니</td>\n",
       "      <td>OSEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>음주운전 사고부담금 최대 1억6500만원..전동킥보드도 차보험 보상</td>\n",
       "      <td>아시아경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>'감사원 발표에 한숨' 월성원전 주민들 \"경제성 없다는 이유 밝혀라\"</td>\n",
       "      <td>뉴스1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[단독] '밥심' 박해미 \"전남편 음주사건 심경 고백 후련, 子 황성재 고마워 눈물...</td>\n",
       "      <td>엑스포츠뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\"야당답지 못하다\"..野원로들, 김종인에 쓴소리</td>\n",
       "      <td>헤럴드경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>무리한 탈원전 정책에 무너진 韓 '원전 생태계'</td>\n",
       "      <td>조선비즈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>이혜리 \"'응팔' 5년만 박보검과 재회, 간식까지 챙겨줘 든든+감사\"[직격인터뷰]</td>\n",
       "      <td>뉴스엔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\"확진자 쏟아지는 부산 북구에 차마\"..순천시,구상권 청구 보류</td>\n",
       "      <td>뉴스1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>편의점 털려던 강도, 가게 갇혀 검거..종업원이 문 막아</td>\n",
       "      <td>동아일보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>27m길이 명나라 그림 850억원에 낙찰..중국 고서화 최고가</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>양주지역 정치인들, 투병생활 '이성호 시장' 자진 퇴진 촉구</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            newstitle newscomname\n",
       "0    김진숙, 문 대통령에 편지 \"옛 동지가 묻는다..언제까지 약자가 약자를 응원해야 하나\"        경향신문\n",
       "1              [단독]\"머리 감기는데 가슴을..\" 요양보호사 42%가 성희롱 당했다       머니투데이\n",
       "2              이인영, 노벨평화상 수상 WFP에 \"선정 축하..北 사업 적극 지원\"         뉴스1\n",
       "3                       '사상초유' 검찰총장까지 수사 받나..이성윤에 달렸다         뉴시스\n",
       "4              [단독]로젠택배 40대 기사, '갑질' 호소 유서 남기고 극단적 선택         뉴스1\n",
       "5              100kg 넘는 아들 목 졸라 살해한 76세 노모에 징역 20년 구형        연합뉴스\n",
       "6                 뭘 먹었길래..중국 14살짜리 중학생 키가 무려 '2m21cm'        연합뉴스\n",
       "7            '국민의짐' 표현 \"사과하라\"..이재명 \"국민의짐 진짜 안 되길 바란다\"         뉴시스\n",
       "8                   \"추미애, 정치적 목적의 윤석열 망신주기\"..법조계 한목소리         뉴스1\n",
       "9               \"외국인 건보혜택 중국인이 71% 차지..5년반 동안 2조4천억원\"        연합뉴스\n",
       "10    [단독] \"불투명 비말 칸막이 때문에 칠판이 안 보여요\".. 초등학교 '깜깜이 수업'        서울신문\n",
       "11            고창서 독감백신 맞은 70대 이튿날 사망..\"인과관계 확인 중\"(종합)        연합뉴스\n",
       "12                  방금전 방송에서 나온 제품이 바로 홈쇼핑에..우연이 아니었다       머니투데이\n",
       "13         \"절도 이력 때문에 해사 불합격\"..법원, 신원조회 위법 \"불합격 취소하라\"        중앙일보\n",
       "14                      코로나에 다 망했다는데..'빵집'만 살아남은 이유는?       헤럴드경제\n",
       "15                  소형 전기밥솥, 보온 기능에 차이..밥 딱딱하게 굳는 제품도         뉴스1\n",
       "16                \"어려운 이웃에게 써달라\" 대전 도마2동에 100만원 익명 기부        연합뉴스\n",
       "17          1억 마세라티·5천 벤츠 몰며 서울 공공임대주택 거주 어떻게 가능?(종합)         뉴시스\n",
       "18            21세 男 1명 1년간 3062회 병원 이용 최다..건보 3천만원 소요         뉴시스\n",
       "19                 국민의힘 \"조국 딸 입학 취소 왜 안 하나\" 부산대 국감 공세        연합뉴스\n",
       "20                 30대 남성의 수상한 기록, 2년여간 식욕억제제 2만정 타갔다       머니투데이\n",
       "21               손흥민 토트넘 잔류시 최고 주급 유력..EPL 톱5 진입 가능성도      스포티비뉴스\n",
       "22                                '콩다방' 커피빈마저 매물로 나왔다       머니투데이\n",
       "23     '10조 빅딜' 이끈 최태원 SK회장의 승부수.. 현상유지만 하는 다른 그룹과 대조        조선비즈\n",
       "24                    전문직 소득 중 의사가 압도적 1위..변호사와 2배 격차        서울신문\n",
       "25                    [단독] 고창서 70대 여성 독감 백신 접종 후 또 사망         더팩트\n",
       "26             '불청' 김홍표 \"교통사고로 4번 대수술, 일용직 조경에 대리운전도\"         뉴스엔\n",
       "27                  환자 저항에 검사하던 보건소 직원 옷 찢어져 '확진'(종합)         뉴시스\n",
       "28                   [단독] 참모들 부른 尹 \"라임 비호세력 처단\" 직접 썼다        국민일보\n",
       "29              秋가 때리면 커지는 윤석열 존재감..'가족 수사' 이번엔 다를 수도         뉴스1\n",
       "30      '노는 언니' 박세리 \"잘생긴 남자만 만났다\" 10년지기 골프 후배들 폭로에 한탄         뉴스엔\n",
       "31                           토트넘 '날벼락'..레알 레길론 재영입 고려      스포티비뉴스\n",
       "32               [예천 육상] \"누구야?!\" 슈퍼유망주 '초미네이터' 등장에 흥분        에스티엔\n",
       "33                   '정경심 안대 퍼포먼스' 5명, 검찰송치..모욕 혐의 적용         뉴시스\n",
       "34              \"밥 굶는 아이 없도록\"..전주 '엄마의 밥상'에 6년간 8억 쇄도        연합뉴스\n",
       "35                            전국노래자랑 현장에서 포착한 대한민국 초상        연합뉴스\n",
       "36                      \"강원랜드 20초만에 털려..열쇠 분실 6년간 몰라\"        서울신문\n",
       "37           [현장연결] 질병청 \"코로나 발생 안정세..이제 1단계 성적표 나올 것\"      연합뉴스TV\n",
       "38            손흥민, \"영어 못하는 느낌 아니까\".. '신입' 비니시우스 돕는 이유      스포탈코리아\n",
       "39               '러시아 미녀' 라자레바, 차원이 다른 대박 외인..한국 왜 왔니        OSEN\n",
       "40              음주운전 사고부담금 최대 1억6500만원..전동킥보드도 차보험 보상       아시아경제\n",
       "41             '감사원 발표에 한숨' 월성원전 주민들 \"경제성 없다는 이유 밝혀라\"         뉴스1\n",
       "42  [단독] '밥심' 박해미 \"전남편 음주사건 심경 고백 후련, 子 황성재 고마워 눈물...      엑스포츠뉴스\n",
       "43                         \"야당답지 못하다\"..野원로들, 김종인에 쓴소리       헤럴드경제\n",
       "44                         무리한 탈원전 정책에 무너진 韓 '원전 생태계'        조선비즈\n",
       "45      이혜리 \"'응팔' 5년만 박보검과 재회, 간식까지 챙겨줘 든든+감사\"[직격인터뷰]         뉴스엔\n",
       "46                \"확진자 쏟아지는 부산 북구에 차마\"..순천시,구상권 청구 보류         뉴스1\n",
       "47                    편의점 털려던 강도, 가게 갇혀 검거..종업원이 문 막아        동아일보\n",
       "48                 27m길이 명나라 그림 850억원에 낙찰..중국 고서화 최고가        연합뉴스\n",
       "49                  양주지역 정치인들, 투병생활 '이성호 시장' 자진 퇴진 촉구         뉴시스"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "title = []\n",
    "media = []\n",
    "urlstr = 'http://media.daum.net/ranking/popular/'\n",
    "r = requests.get(urlstr)\n",
    "r.encoding = \"utf-8\"\n",
    "bs = BeautifulSoup(r.text, 'html.parser')\n",
    "titleList = bs.select('ul.list_news2 > li > div.cont_thumb > strong > a')\n",
    "mediaList = bs.select('ul.list_news2 > li > div.cont_thumb > strong > span')\n",
    "\n",
    "for titleDom in titleList:\n",
    "\ttitle.append(titleDom.string)\n",
    "for mediaDom in mediaList:\n",
    "\tmedia.append(mediaDom.string)\n",
    "\n",
    "# with open('C:/Temp/news.csv', \"wt\", encoding=\"utf-8\") as f:\n",
    "#    f.write('newstitle,newscomname \\n')  \n",
    "#    for i in range(len(title)):\n",
    "#        f.write(\"\\\"\" + title[i] + \"\\\", \\\"\" + media[i] + \"\\\"\" + \"\\n\")  \n",
    "#        print(\"\\\"\" + title[i] + \"\\\", \\\"\" + media[i] + \"\\\"\" + \"\\n\")\n",
    "\n",
    "df = pd.DataFrame({'newstitle':title, 'newscomname':media})\n",
    "print(df)\n",
    "display(df)\n",
    "df.to_csv(\"C:/Temp/news2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 page 상품명 누적 8개 적재\n",
      "1 page 가격 누적 8개 적재\n",
      "2 page 상품명 누적 16개 적재\n",
      "2 page 가격 누적 16개 적재\n",
      "3 page 상품명 누적 24개 적재\n",
      "3 page 가격 누적 24개 적재\n",
      "4 page 상품명 누적 32개 적재\n",
      "4 page 가격 누적 32개 적재\n",
      "5 page 상품명 누적 40개 적재\n",
      "5 page 가격 누적 40개 적재\n",
      "6 page 상품명 누적 48개 적재\n",
      "6 page 가격 누적 48개 적재\n",
      "7 page 상품명 누적 56개 적재\n",
      "7 page 가격 누적 56개 적재\n",
      "8 page 상품명 누적 64개 적재\n",
      "8 page 가격 누적 64개 적재\n",
      "9 page 상품명 누적 72개 적재\n",
      "9 page 가격 누적 72개 적재\n",
      "10 page 상품명 누적 80개 적재\n",
      "10 page 가격 누적 80개 적재\n",
      "11 page 상품명 누적 88개 적재\n",
      "11 page 가격 누적 88개 적재\n",
      "12 page 상품명 누적 96개 적재\n",
      "12 page 가격 누적 96개 적재\n",
      "13 page 상품명 누적 104개 적재\n",
      "13 page 가격 누적 104개 적재\n",
      "14 page 상품명 누적 112개 적재\n",
      "14 page 가격 누적 112개 적재\n",
      "15 page 상품명 누적 120개 적재\n",
      "15 page 가격 누적 120개 적재\n",
      "16 page 상품명 누적 128개 적재\n",
      "16 page 가격 누적 128개 적재\n",
      "17 page 상품명 누적 136개 적재\n",
      "17 page 가격 누적 136개 적재\n",
      "18 page 상품명 누적 144개 적재\n",
      "18 page 가격 누적 144개 적재\n",
      "19 page 상품명 누적 152개 적재\n",
      "19 page 가격 누적 152개 적재\n",
      "20 page 상품명 누적 160개 적재\n",
      "20 page 가격 누적 160개 적재\n",
      "21 page 상품명 누적 168개 적재\n",
      "21 page 가격 누적 168개 적재\n",
      "22 page 상품명 누적 176개 적재\n",
      "22 page 가격 누적 176개 적재\n",
      "23 page 상품명 누적 184개 적재\n",
      "23 page 가격 누적 184개 적재\n",
      "24 page 상품명 누적 192개 적재\n",
      "24 page 가격 누적 192개 적재\n",
      "25 page 상품명 누적 200개 적재\n",
      "25 page 가격 누적 200개 적재\n",
      "26 page 상품명 누적 208개 적재\n",
      "26 page 가격 누적 208개 적재\n",
      "27 page 상품명 누적 216개 적재\n",
      "27 page 가격 누적 216개 적재\n",
      "28 page 상품명 누적 224개 적재\n",
      "28 page 가격 누적 224개 적재\n",
      "29 page 상품명 누적 232개 적재\n",
      "29 page 가격 누적 232개 적재\n",
      "30 page 상품명 누적 240개 적재\n",
      "30 page 가격 누적 240개 적재\n",
      "31 page 상품명 누적 248개 적재\n",
      "31 page 가격 누적 248개 적재\n",
      "32 page 상품명 누적 256개 적재\n",
      "32 page 가격 누적 256개 적재\n",
      "33 page 상품명 누적 264개 적재\n",
      "33 page 가격 누적 264개 적재\n",
      "34 page 상품명 누적 272개 적재\n",
      "34 page 가격 누적 272개 적재\n",
      "35 page 상품명 누적 280개 적재\n",
      "35 page 가격 누적 280개 적재\n",
      "36 page 상품명 누적 288개 적재\n",
      "36 page 가격 누적 288개 적재\n",
      "37 page 상품명 누적 296개 적재\n",
      "37 page 가격 누적 296개 적재\n",
      "38 page 상품명 누적 304개 적재\n",
      "38 page 가격 누적 304개 적재\n",
      "39 page 상품명 누적 312개 적재\n",
      "39 page 가격 누적 312개 적재\n",
      "40 page 상품명 누적 320개 적재\n",
      "40 page 가격 누적 320개 적재\n",
      "41 page 상품명 누적 328개 적재\n",
      "41 page 가격 누적 328개 적재\n",
      "42 page 상품명 누적 336개 적재\n",
      "42 page 가격 누적 336개 적재\n",
      "43 page 상품명 누적 344개 적재\n",
      "43 page 가격 누적 344개 적재\n",
      "44 page 상품명 누적 352개 적재\n",
      "44 page 가격 누적 352개 적재\n",
      "45 page 상품명 누적 360개 적재\n",
      "45 page 가격 누적 360개 적재\n",
      "46 page 상품명 누적 368개 적재\n",
      "46 page 가격 누적 368개 적재\n",
      "47 page 상품명 누적 376개 적재\n",
      "47 page 가격 누적 376개 적재\n",
      "48 page 상품명 누적 384개 적재\n",
      "48 page 가격 누적 384개 적재\n",
      "49 page 상품명 누적 392개 적재\n",
      "49 page 가격 누적 392개 적재\n",
      "50 page 상품명 누적 400개 적재\n",
      "50 page 가격 누적 400개 적재\n",
      "51 page 상품명 누적 408개 적재\n",
      "51 page 가격 누적 408개 적재\n",
      "52 page 상품명 누적 416개 적재\n",
      "52 page 가격 누적 416개 적재\n",
      "53 page 상품명 누적 424개 적재\n",
      "53 page 가격 누적 424개 적재\n",
      "54 page 상품명 누적 432개 적재\n",
      "54 page 가격 누적 432개 적재\n",
      "55 page 상품명 누적 440개 적재\n",
      "55 page 가격 누적 440개 적재\n",
      "56 page 상품명 누적 448개 적재\n",
      "56 page 가격 누적 448개 적재\n",
      "57 page 상품명 누적 456개 적재\n",
      "57 page 가격 누적 456개 적재\n",
      "58 page 상품명 누적 464개 적재\n",
      "58 page 가격 누적 464개 적재\n",
      "59 page 상품명 누적 472개 적재\n",
      "59 page 가격 누적 472개 적재\n",
      "60 page 상품명 누적 480개 적재\n",
      "60 page 가격 누적 480개 적재\n",
      "61 page 상품명 누적 488개 적재\n",
      "61 page 가격 누적 488개 적재\n",
      "62 page 상품명 누적 496개 적재\n",
      "62 page 가격 누적 496개 적재\n",
      "63 page 상품명 누적 504개 적재\n",
      "63 page 가격 누적 504개 적재\n",
      "64 page 상품명 누적 512개 적재\n",
      "64 page 가격 누적 512개 적재\n",
      "65 page 상품명 누적 520개 적재\n",
      "65 page 가격 누적 520개 적재\n",
      "66 page 상품명 누적 528개 적재\n",
      "66 page 가격 누적 528개 적재\n",
      "67 page 상품명 누적 536개 적재\n",
      "67 page 가격 누적 536개 적재\n",
      "68 page 상품명 누적 544개 적재\n",
      "68 page 가격 누적 544개 적재\n",
      "69 page 상품명 누적 552개 적재\n",
      "69 page 가격 누적 552개 적재\n",
      "70 page 상품명 누적 560개 적재\n",
      "70 page 가격 누적 560개 적재\n",
      "71 page 상품명 누적 568개 적재\n",
      "71 page 가격 누적 568개 적재\n",
      "72 page 상품명 누적 576개 적재\n",
      "72 page 가격 누적 576개 적재\n",
      "73 page 상품명 누적 584개 적재\n",
      "73 page 가격 누적 584개 적재\n",
      "74 page 상품명 누적 592개 적재\n",
      "74 page 가격 누적 592개 적재\n",
      "75 page 상품명 누적 600개 적재\n",
      "75 page 가격 누적 600개 적재\n",
      "76 page 상품명 누적 608개 적재\n",
      "76 page 가격 누적 608개 적재\n",
      "77 page 상품명 누적 616개 적재\n",
      "77 page 가격 누적 616개 적재\n",
      "78 page 상품명 누적 624개 적재\n",
      "78 page 가격 누적 624개 적재\n",
      "79 page 상품명 누적 632개 적재\n",
      "79 page 가격 누적 632개 적재\n",
      "80 page 상품명 누적 640개 적재\n",
      "80 page 가격 누적 640개 적재\n",
      "81 page 상품명 누적 648개 적재\n",
      "81 page 가격 누적 648개 적재\n",
      "82 page 상품명 누적 656개 적재\n",
      "82 page 가격 누적 656개 적재\n",
      "83 page 상품명 누적 664개 적재\n",
      "83 page 가격 누적 664개 적재\n",
      "84 page 상품명 누적 672개 적재\n",
      "84 page 가격 누적 672개 적재\n",
      "85 page 상품명 누적 680개 적재\n",
      "85 page 가격 누적 680개 적재\n",
      "86 page 상품명 누적 688개 적재\n",
      "86 page 가격 누적 688개 적재\n",
      "87 page 상품명 누적 696개 적재\n",
      "87 page 가격 누적 696개 적재\n",
      "88 page 상품명 누적 704개 적재\n",
      "88 page 가격 누적 704개 적재\n",
      "89 page 상품명 누적 712개 적재\n",
      "89 page 가격 누적 712개 적재\n",
      "90 page 상품명 누적 720개 적재\n",
      "90 page 가격 누적 720개 적재\n",
      "91 page 상품명 누적 728개 적재\n",
      "91 page 가격 누적 728개 적재\n",
      "92 page 상품명 누적 736개 적재\n",
      "92 page 가격 누적 736개 적재\n",
      "93 page 상품명 누적 739개 적재\n",
      "93 page 가격 누적 739개 적재\n",
      "               goodsname goodsprice\n",
      "0       롯데)아이시스8.0(2.0L)       1700\n",
      "1    유어스(P)할리스리스트레또300ML       2500\n",
      "2     유어스(P)할리스콜드브루300ML       2500\n",
      "3        OKF)알로에베라킹500ML       1900\n",
      "4      팜트리)궁중발효홍삼세트(10입)      22000\n",
      "..                   ...        ...\n",
      "734     CJ)맥스봉청양고추후랑크80G       2000\n",
      "735        CJ)직화구이꼬치바90G       2000\n",
      "736        CJ)스팸구이꼬치바80G       2500\n",
      "737   유어스(P)2가지치즈소시지100G       1700\n",
      "738   유어스(P)정통프랑크소시지100G       1700\n",
      "\n",
      "[739 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodsname</th>\n",
       "      <th>goodsprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>롯데)아이시스8.0(2.0L)</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>유어스(P)할리스리스트레또300ML</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>유어스(P)할리스콜드브루300ML</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OKF)알로에베라킹500ML</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>팜트리)궁중발효홍삼세트(10입)</td>\n",
       "      <td>22000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>CJ)맥스봉청양고추후랑크80G</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>CJ)직화구이꼬치바90G</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>CJ)스팸구이꼬치바80G</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>유어스(P)2가지치즈소시지100G</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>유어스(P)정통프랑크소시지100G</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               goodsname goodsprice\n",
       "0       롯데)아이시스8.0(2.0L)       1700\n",
       "1    유어스(P)할리스리스트레또300ML       2500\n",
       "2     유어스(P)할리스콜드브루300ML       2500\n",
       "3        OKF)알로에베라킹500ML       1900\n",
       "4      팜트리)궁중발효홍삼세트(10입)      22000\n",
       "..                   ...        ...\n",
       "734     CJ)맥스봉청양고추후랑크80G       2000\n",
       "735        CJ)직화구이꼬치바90G       2000\n",
       "736        CJ)스팸구이꼬치바80G       2500\n",
       "737   유어스(P)2가지치즈소시지100G       1700\n",
       "738   유어스(P)정통프랑크소시지100G       1700\n",
       "\n",
       "[739 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome('C:/Temp/chromedriver')\n",
    "driver.get(\"http://gs25.gsretail.com/gscvs/ko/products/event-goods\")\n",
    "time.sleep(2)\n",
    "\n",
    "# 2+1행사 탭으로 이동\n",
    "twoPlusOnetab = driver.find_element_by_css_selector('#TWO_TO_ONE')\n",
    "twoPlusOnetab.click()\n",
    "time.sleep(1)\n",
    "\n",
    "titleList_all = []\n",
    "priceList_all = []\n",
    "page = 0\n",
    "\n",
    "while True :\n",
    "    page += 1\n",
    "    \n",
    "    titleList = driver.find_elements_by_css_selector('div.cnt_section.mt50 div > p.tit')\n",
    "    priceList = driver.find_elements_by_css_selector('div.cnt_section.mt50 div > p.price > span')\n",
    "\n",
    "    productCount = 0\n",
    "    for oneTitle in titleList :\n",
    "        if len(oneTitle.text.strip()) > 0 :\n",
    "            titleList_all.append(oneTitle.text.strip())\n",
    "            productCount += 1\n",
    "            # print(oneTitle.text.strip())\n",
    "    print(str(page) + \" page 상품명 누적 \" + str(len(titleList_all)) + \"개 적재\")\n",
    "\n",
    "    for onePrice in priceList :\n",
    "        if len(onePrice.text.strip()) > 0 :\n",
    "            content = re.sub('[^0-9]', '', onePrice.text.strip())\n",
    "            priceList_all.append(content)\n",
    "            # print(content)\n",
    "    print(str(page) + \" page 가격 누적 \" + str(len(priceList_all)) + \"개 적재\")\n",
    "\n",
    "    # 마지막 페이지이면 정지\n",
    "    if productCount < 8 : break  \n",
    "    \n",
    "    # 다음페이지로 이동 - 잘 안되서 스크립트로\n",
    "    driver.execute_script(\"goodsPageController.moveControl(1)\")\n",
    "    time.sleep(1)\n",
    "\n",
    "#with open('C:/Temp/gs25_twotoone.csv', \"wt\", encoding=\"utf-8\") as f:\n",
    "#    f.write('goodsname,goodsprice \\n')  \n",
    "#    for i in range(len(titleList_all)):\n",
    "#        f.write(titleList_all[i] + \",\"+ priceList_all[i] + '\\n') \n",
    "        \n",
    "df = pd.DataFrame({'goodsname':titleList_all, 'goodsprice':priceList_all})\n",
    "print(df)\n",
    "display(df)\n",
    "df.to_csv(\"C:/Temp/gs25_twotoone2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
